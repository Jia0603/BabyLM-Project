model_name: Zhe-Zhang/GPT2-Small-BabyLM-CE
revision_name: None
learning_rate: 1e-6
log_with: wandb
hf_org : Zhe-Zhang



# Trainer Settings
num_epochs: 1
batch_size: 360
token_limit: 1000000
# checkpoint_interval: 200000
save_base_dir: saved_models/


#query settings (range for sampling length of student input)
query_min_length: 1
query_max_length: 8


data_path: data/ppo/

# Output generation
generation_kwargs:
  min_length: -1
  max_new_tokens: 90
  top_k: 0
  top_p: 1
  do_sample: true
  num_beams: 1
